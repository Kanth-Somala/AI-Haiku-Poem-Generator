{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kanth-Somala/AI-Haiku-Poem-Generator/blob/main/AI_Genrated_Haiku_Poems.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AlAztDZ--krd"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets accelerate --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thy4z61g-P2B"
      },
      "outputs": [],
      "source": [
        "# Load haiku file\n",
        "file_path = '/content/lines.txt'\n",
        "\n",
        "with open(file_path, 'r', encoding='utf-8') as f:\n",
        "    raw_text = f.read()\n",
        "\n",
        "# Split by '$' and convert each haiku into 3-line format\n",
        "raw_haikus = [h.strip() for h in raw_text.split('$') if h.strip()]\n",
        "\n",
        "formatted_haikus = []\n",
        "for h in raw_haikus:\n",
        "    parts = [line.strip() for line in h.split('/') if line.strip()]\n",
        "    if len(parts) == 3:\n",
        "        formatted_haikus.append('\\n'.join(parts))  # maintain 3-line format\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "dataset = Dataset.from_dict({\"text\": formatted_haikus})\n"
      ],
      "metadata": {
        "id": "yzu5DQdQ_gXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "def tokenize_function(example):\n",
        "    tokens = tokenizer(example[\"text\"], padding=\"max_length\", truncation=True, max_length=50)\n",
        "    tokens[\"labels\"] = tokens[\"input_ids\"].copy()\n",
        "    return tokens\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenize_function)\n"
      ],
      "metadata": {
        "id": "P_ZDZJnN_lV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, TrainingArguments, Trainer\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./haiku-gpt2\",\n",
        "    per_device_train_batch_size=4,\n",
        "    num_train_epochs=5,\n",
        "    logging_steps=10,\n",
        "    save_strategy=\"epoch\",\n",
        "    fp16=False,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        ")\n"
      ],
      "metadata": {
        "id": "rIW1Jzje_yMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9726c20b"
      },
      "source": [
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"./haiku-gpt2-finetuned\")\n",
        "tokenizer.save_pretrained(\"./haiku-gpt2-finetuned\")"
      ],
      "metadata": {
        "id": "HB0TzvAqE85p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "generator = pipeline(\"text-generation\", model=\"./haiku-gpt2-finetuned\", tokenizer=\"./haiku-gpt2-finetuned\")\n",
        "\n",
        "prompt = \"nature is awsome\"\n",
        "outputs = generator(prompt, max_new_tokens=40, num_return_sequences=3, do_sample=True, top_k=50)\n",
        "\n",
        "for i, output in enumerate(outputs):\n",
        "    print(f\"\\nHaiku {i+1}:\\n{output['generated_text']}\")\n"
      ],
      "metadata": {
        "id": "4J9JKKS7FCY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install syllables --quiet\n"
      ],
      "metadata": {
        "id": "8GeJJx3CHPxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import syllables\n",
        "from transformers import pipeline\n",
        "\n",
        "prompt = input(\"Enter a haiku theme: \")\n",
        "\n",
        "generator = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=\"./haiku-gpt2-finetuned\",\n",
        "    tokenizer=\"./haiku-gpt2-finetuned\"\n",
        ")\n",
        "\n",
        "outputs = generator(\n",
        "    prompt,\n",
        "    max_new_tokens=40,\n",
        "    num_return_sequences=100,\n",
        "    do_sample=True,\n",
        "    top_k=50\n",
        ")\n",
        "\n",
        "def count_syllables(line):\n",
        "    return sum(syllables.estimate(word) for word in line.split())\n",
        "\n",
        "def is_valid_575(lines):\n",
        "    return (\n",
        "        len(lines) == 3 and\n",
        "        count_syllables(lines[0]) == 5 and\n",
        "        count_syllables(lines[1]) == 7 and\n",
        "        count_syllables(lines[2]) == 5\n",
        "    )\n",
        "\n",
        "def extract_haiku(text):\n",
        "    lines = [line.strip() for line in text.split('\\n') if line.strip()]\n",
        "    if is_valid_575(lines):\n",
        "        return lines\n",
        "    words = text.strip().split()\n",
        "    if len(words) < 17:\n",
        "        return None\n",
        "    candidate_lines = [\n",
        "        \" \".join(words[:5]),\n",
        "        \" \".join(words[5:12]),\n",
        "        \" \".join(words[12:17])\n",
        "    ]\n",
        "    if is_valid_575(candidate_lines):\n",
        "        return candidate_lines\n",
        "    return None\n",
        "\n",
        "valid_haikus = []\n",
        "for output in outputs:\n",
        "    text = output[\"generated_text\"]\n",
        "    haiku = extract_haiku(text)\n",
        "    if haiku:\n",
        "        valid_haikus.append(haiku)\n",
        "        if len(valid_haikus) >= 3:\n",
        "            break\n",
        "\n",
        "if valid_haikus:\n",
        "    print(\"\\n Haikus Generated:\")\n",
        "    for idx, haiku in enumerate(valid_haikus, 1):\n",
        "        print(f\"\\nüåø Haiku {idx}:\")\n",
        "        for line in haiku:\n",
        "            print(f\"{line}\")\n",
        "else:\n",
        "    print(\"\\n‚ùå No valid 5-7-5 haikus were found. Try another theme or generate more.\")\n"
      ],
      "metadata": {
        "id": "644t6qEFLTop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "syllables.estimate('becarefulfolks')"
      ],
      "metadata": {
        "id": "45g4S2WdMhjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nbstripout\n",
        "!nbstripout AI Genrated Haiku Poems.ipynb\n"
      ],
      "metadata": {
        "id": "RQvv5A5nMu0o"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyN51/U4ZiImME7ababXXUTL",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}